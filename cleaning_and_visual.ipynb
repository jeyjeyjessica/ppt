{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKbhZbDueWhO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/amazon (2).csv')\n",
        "display(df)\n",
        "column_names = df.columns.tolist()\n",
        "print(column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'a-profile-name': 'Username','a-icon-alt':'Rating','a-size-base':'Review Heading','a-size-base 3':'Detailed Review','a-size-base 2':'Date'}, inplace=True)\n",
        "column_names = df.columns.tolist()\n",
        "print(column_names)"
      ],
      "metadata": {
        "id": "PS_9Gl4rLJog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_columns = ['Username','Rating','Review Heading','Date','Detailed Review']\n",
        "df = df[modified_columns]\n",
        "\n",
        "column_names = df.columns.tolist()\n",
        "display(df)\n",
        "print(column_names)"
      ],
      "metadata": {
        "id": "jXFylP-uLLlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = df.isnull().sum()\n",
        "print(\"Null values in each column:\")\n",
        "print(null_values)"
      ],
      "metadata": {
        "id": "Tq_wxwkoLN3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = df[df.duplicated()]\n",
        "\n",
        "if duplicate_rows.empty:\n",
        "    print(\"No duplicate rows found.\")\n",
        "else:\n",
        "    print(\"Duplicate rows:\")\n",
        "    print(duplicate_rows)"
      ],
      "metadata": {
        "id": "Tb6uV7RTLQ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymous_rows = df[df['Username'] == 'Anonymous']\n",
        "print(anonymous_rows)"
      ],
      "metadata": {
        "id": "Pdv9DXzULS81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rating'] = df['Rating'].str.split(' out of 5 stars').str[0]\n",
        "\n",
        "print(df['Rating'])"
      ],
      "metadata": {
        "id": "BGFsHKNALW7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = df['Date'].str.replace('Reviewed in the United States on ', '')\n",
        "display(df['Date'])"
      ],
      "metadata": {
        "id": "_-ylDfVyLXXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "F6leh5ueLaOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/amazon (1).csv')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('punkt')\n",
        "\n",
        "df = pd.DataFrame(df1)\n",
        "\n",
        "# Function to extract bigrams\n",
        "def extract_bigrams(text):\n",
        "    tokens = word_tokenize(text)  # Tokenize the text\n",
        "    bigrams = list(ngrams(tokens, 2))  # Extract bigrams\n",
        "    return bigrams\n",
        "\n",
        "# Apply the function to each row of the DataFrame\n",
        "df['bigrams'] = df['Detailed review'].apply(extract_bigrams)\n",
        "\n",
        "# Flatten the list of bigrams and count occurrences\n",
        "bigram_counts = {}\n",
        "for bigrams_list in df['bigrams']:\n",
        "    for bigram in bigrams_list:\n",
        "        if bigram in bigram_counts:\n",
        "            bigram_counts[bigram] += 1\n",
        "        else:\n",
        "            bigram_counts[bigram] = 1\n",
        "\n",
        "# Display the count of each bigram\n",
        "print(\"Bigram Counts:\")\n",
        "for bigram, count in bigram_counts.items():\n",
        "    print(bigram, \":\", count)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F5b6bScAOir_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import ngrams\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "df = pd.DataFrame(df1)\n",
        "\n",
        "# Function to extract bigrams of adjectives\n",
        "def extract_adj_bigrams(text):\n",
        "    tokens = word_tokenize(text)  # Tokenize the text\n",
        "    tagged_tokens = pos_tag(tokens)  # Perform POS tagging\n",
        "    adjectives = [word for word, tag in tagged_tokens if tag.startswith('JJ')]  # Filter adjectives\n",
        "    adj_bigrams = list(ngrams(adjectives, 1))  # Extract bigrams of adjectives\n",
        "    return adj_bigrams\n",
        "\n",
        "# Apply the function to each row of the DataFrame\n",
        "df['adj_bigrams'] = df['Detailed review'].apply(extract_adj_bigrams)\n",
        "\n",
        "# Flatten the list of bigrams and count occurrences\n",
        "adj_bigram_counts = {}\n",
        "for adj_bigrams_list in df['adj_bigrams']:\n",
        "    for adj_bigram in adj_bigrams_list:\n",
        "        if adj_bigram in adj_bigram_counts:\n",
        "            adj_bigram_counts[adj_bigram] += 1\n",
        "        else:\n",
        "            adj_bigram_counts[adj_bigram] = 1\n",
        "\n",
        "# Display the count of each adjective bigram\n",
        "print(\"Adjective Bigram Counts:\")\n",
        "for adj_bigram, count in adj_bigram_counts.items():\n",
        "    print(adj_bigram, \":\", count)\n"
      ],
      "metadata": {
        "id": "_Q-507OIOjYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_adj_bigram_counts = {adj_bigram: count for adj_bigram, count in adj_bigram_counts.items() if count > 5}\n",
        "\n",
        "# Display the count of each adjective bigram with count more than 5\n",
        "print(\"Adjective Bigram Counts (Count > 5):\")\n",
        "for adj_bigram, count in filtered_adj_bigram_counts.items():\n",
        "    print(adj_bigram, \":\", count)"
      ],
      "metadata": {
        "id": "qaEKpQ-QOm5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import ngrams\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "df1 = pd.read_csv('/content/amazon (1).csv')\n",
        "df = pd.DataFrame(df1)\n",
        "\n",
        "# Function to extract bigrams of noun-adjective pairs\n",
        "def extract_noun_adj_bigrams(text):\n",
        "    tokens = word_tokenize(text)  # Tokenize the text\n",
        "    tagged_tokens = pos_tag(tokens)  # Perform POS tagging\n",
        "    noun_adj_pairs = [(tagged_tokens[i][0], tagged_tokens[i+1][0])\n",
        "                      for i in range(len(tagged_tokens)-1)\n",
        "                      if tagged_tokens[i][1].startswith('NN') and tagged_tokens[i+1][1].startswith('JJ')]\n",
        "    return noun_adj_pairs\n",
        "\n",
        "# Apply the function to each row of the DataFrame\n",
        "df['noun_adj_bigrams'] = df['Detailed review'].apply(extract_noun_adj_bigrams)\n",
        "\n",
        "# Flatten the list of bigrams and count occurrences\n",
        "noun_adj_bigram_counts = {}\n",
        "for noun_adj_bigrams_list in df['noun_adj_bigrams']:\n",
        "    for noun_adj_bigram in noun_adj_bigrams_list:\n",
        "        if noun_adj_bigram in noun_adj_bigram_counts:\n",
        "            noun_adj_bigram_counts[noun_adj_bigram] += 1\n",
        "        else:\n",
        "            noun_adj_bigram_counts[noun_adj_bigram] = 1\n",
        "\n",
        "# Display the count of each noun-adjective bigram\n",
        "print(\"Noun-Adjective Bigram Counts:\")\n",
        "for noun_adj_bigram, count in noun_adj_bigram_counts.items():\n",
        "    print(noun_adj_bigram, \":\", count)\n"
      ],
      "metadata": {
        "id": "ZN2Nn_yvOqgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a string of all noun-adjective pairs\n",
        "text = ' '.join([' '.join(pair) for pair in noun_adj_bigram_counts.keys()])\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PvshlhwrOzod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a string of all adjectives\n",
        "text = ' '.join([' '.join(pair) for pair in filtered_adj_bigram_counts.keys()])\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zcR-Q1BeO15U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Bar Plot of Ratings\n",
        "plt.figure(figsize=(8, 6))\n",
        "df['Rating'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', linewidth=1.2)\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', linestyle='', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Word Cloud of Review Headings\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['Review Heading']))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud of Review Headings')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Time Series Plot of Reviews Over Time (Yearly)\n",
        "plt.figure(figsize=(10, 6))\n",
        "df.groupby(df['Date'].dt.year).size().plot(marker='o', linestyle='-')\n",
        "plt.title('Number of Reviews Over Time (Yearly)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.xticks(range(df['Date'].dt.year.min(), df['Date'].dt.year.max() + 1))\n",
        "plt.grid(True, axis='y', linestyle='')\n",
        "plt.show()\n",
        "\n",
        "# Histogram of Review Lengths\n",
        "df['Review Length'] = df['Detailed Review'].apply(lambda x: len(x.split()))\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(df['Review Length'], bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.xlabel('Review Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, axis='y', linestyle='')\n",
        "plt.show()\n",
        "\n",
        "# Time Series Plot of Reviews Over Time by Month\n",
        "plt.figure(figsize=(10, 6))\n",
        "df.groupby(df['Date'].dt.month).size().plot(marker='o', linestyle='-')\n",
        "plt.title('Number of Reviews Over Time (Monthly)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True, axis='y', linestyle='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HKXCEUnzLdDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}